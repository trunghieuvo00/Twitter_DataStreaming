{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ReadDataFromStream.ipynb","provenance":[],"mount_file_id":"1xQUi9izRGfkFfmqOSWW1rb8B8goCaHPJ","authorship_tag":"ABX9TyMIIEh/a8esPf/Mp/3JbQOs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wG0wWlDGhe03","executionInfo":{"status":"ok","timestamp":1624630541043,"user_tz":-420,"elapsed":39134,"user":{"displayName":"Võ Trung Hiếu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1XtGREr8M2AEMnVVCceBKR1Hec_FnEvtXjZLCqtk=s64","userId":"02697043291370318281"}},"outputId":"7d7c73a9-cd53-4399-d4ea-46264bde6ff6"},"source":["!pip install pyspark"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting pyspark\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/db/e18cfd78e408de957821ec5ca56de1250645b05f8523d169803d8df35a64/pyspark-3.1.2.tar.gz (212.4MB)\n","\u001b[K     |████████████████████████████████| 212.4MB 67kB/s \n","\u001b[?25hCollecting py4j==0.10.9\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n","\u001b[K     |████████████████████████████████| 204kB 19.2MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=e97f6477c291fc4a4991df5115759cfbb8b5206cb559bfafbae08b412e2fc62a\n","  Stored in directory: /root/.cache/pip/wheels/40/1b/2c/30f43be2627857ab80062bef1527c0128f7b4070b6b2d02139\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9 pyspark-3.1.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xi2Yhv5wjb5v","executionInfo":{"status":"ok","timestamp":1624631013903,"user_tz":-420,"elapsed":3466,"user":{"displayName":"Võ Trung Hiếu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1XtGREr8M2AEMnVVCceBKR1Hec_FnEvtXjZLCqtk=s64","userId":"02697043291370318281"}},"outputId":"bdd61e7e-1bef-4363-bb3b-ea52f1ff1fd4"},"source":["!pip install findspark"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Collecting findspark\n","  Downloading https://files.pythonhosted.org/packages/fc/2d/2e39f9a023479ea798eed4351cd66f163ce61e00c717e03c37109f00c0f2/findspark-1.4.2-py2.py3-none-any.whl\n","Installing collected packages: findspark\n","Successfully installed findspark-1.4.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xUwLiLwjg52G","executionInfo":{"status":"ok","timestamp":1624630625392,"user_tz":-420,"elapsed":295,"user":{"displayName":"Võ Trung Hiếu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1XtGREr8M2AEMnVVCceBKR1Hec_FnEvtXjZLCqtk=s64","userId":"02697043291370318281"}}},"source":["import pyspark\n","from IPython.display import display, clear_output\n","from pyspark.sql import SparkSession, DataFrame\n","from pyspark.sql import functions as f\n","import pandas as pd\n","from pyspark.ml import Pipeline\n","from pyspark.sql.functions import udf\n","from pyspark.sql.streaming import DataStreamReader\n","import html"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XSaRfnYNiAZg","executionInfo":{"status":"ok","timestamp":1624633101415,"user_tz":-420,"elapsed":845,"user":{"displayName":"Võ Trung Hiếu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1XtGREr8M2AEMnVVCceBKR1Hec_FnEvtXjZLCqtk=s64","userId":"02697043291370318281"}},"outputId":"ebccdca5-0567-4f69-ce74-ef429770e4e4"},"source":["#SETUP\n","IN_PATH = \"/content/drive/MyDrive/Study/Big Data/Assignment10/DataStreaming\"\n","\n","spark = SparkSession.builder.appName(\"Streaming\").getOrCreate()\n","\n","timestampformat = \"EEE MMM dd HH:mm:ss zzzz yyyy\"\n","spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\n","spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n","\n","# schema = spark.read.json(IN_PATH).limit(10).schema\n","schema = spark.read.json(\"/content/drive/MyDrive/Study/Big Data/Assignment10/LabelTest.json\")\n","# spark_reader = spark.readStream.schema(schema)\n","schema"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<bound method DataType.json of StructType(List(StructField(_corrupt_record,StringType,true)))>"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"KjkgpMa9kGQG"},"source":[""],"execution_count":null,"outputs":[]}]}